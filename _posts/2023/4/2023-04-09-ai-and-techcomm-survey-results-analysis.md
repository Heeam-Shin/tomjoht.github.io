---
title: "Survey analysis: AI's impact on tech comm"
categories:
- technical-writing
keywords:
rebrandly: https://idbwrtng.com/
description: "I recently conducted an informal survey to find out the impact of AI on tech comm. 291 people responded to the survey. Below are my comments on the responses."
published: false
---

<h2>General survey of information</h2>

* Date the survey was available: April 3 to April 19 (one week)
* Means of promotion: my blog, newsletter, Linkedin, and Twitter
* Survey participant locations: US: 42%, India: 12%, Canada: 6%, Germany: 4%, Great Britain: 4%
* Average time participants spent on the survey: 6 minutes  

<a href="https://idbwrtng.com/ai-survey-tech-comm-results"><img src="https://s3.us-west-1.wasabisys.com/idbwmedia.com/images/aitechcommsurvey_people.png" alt="Survey demographics" /></a>

The survey questions and responses in raw form are [here on QuestionPro](https://idbwrtng.com/ai-survey-tech-comm-results).


<h2>1. Given AI tools' ability to simplify complex content, how worried are you about the future of your job as a technical writer?</h2>

<img src="https://s3.us-west-1.wasabisys.com/idbwmedia.com/images/aitechcommsurvey1.png" alt="Question 1" />

With *46% mildly concerned, 22% concerned, and 9% very concerned,* it's safe to say that this is a huge issue in the industry. Not sure if there's ever been another technology that has made nearly half the industry mildly concerned, a quarter concerned. For those individuals truly freaking out, how does this manifest itself? Do you find yourself pacing randomly in corporate hallways with tight fists?

<h2>2. If the technical writer role vanishes in a few years, which profession would you most likely transition to (assuming you're a tech writer now)? </h2>

<img src="https://s3.us-west-1.wasabisys.com/idbwmedia.com/images/aitechcommsurvey2.png" alt="Question 2" />

**Top responses:**

* *Content strategist: 16%*
* *Information architect: 16%*
* *User experience designer: 10%*
* *Instructional designer: 8%*
* *Business analyst: 7%*
* *AI-generated content ghostwriter: 7%*

I left out UX writer and product manager, prompt engineer from the response options. Some self-written responses: Cat sitters, farmers, and homesteaders. Interesting responses for content strategy and information architect because most technical writers do a degree of this already. Anytime you plan content for a large project and strive to make it match the marcom content, you're doing content strategy. When you plan the information flow in your developer portal, how findable the topics are, you're doing IA.

Personally, I find both content strategy and information architecture compelling. These focuses seem to align with more recent focus on systems thinking. 

One question is whether these other disciplines are equally at risk. Given that writing isn't their primary artifact, perhaps not. Currently, there are a great many "technical writer" jobs open. Will we see this role evolve to more content strategists and information architects? I'm not sure.

<h2>3. Given that writing makes up only a fraction of a technical writer's tasks, how likely is it that AI tools will have a transformative impact on tech comm?</h2>

<img src="https://s3.us-west-1.wasabisys.com/idbwmedia.com/images/aitechcommsurvey3.png" alt="Question 3" />

With *42% likely and 23% very likely,* then yes most people feel it will be transformative. This is an interesting perspective because it means the greatest transformation won't just be in AI's ability to write docs. Think about the other influences of AI, which I mentioned in a later question.

<h2>4. Because AI can read, explain, and generate code pretty well, will developer doc jobs be more impacted than more creative-oriented writing jobs?</h2>

<img src="https://s3.us-west-1.wasabisys.com/idbwmedia.com/images/aitechcommsurvey4.png" alt="Question 4" />

With *44% likely and 22% very likely,* we can consider this a done deal. Most significant transformations to occur in API docs! Will we see a shift back toward less technical documentation? What about all those technical skillsets people spent so long accruing? Is that technical depth no longer something that gives you a leg up on other tech writer candidates? On the other hand, articles like Kayce Basques's post on the [role of plugins with ChatGTP](https://technicalwriting.tools/posts/chatgpt-plugins/) suggests that accurate, clear, and comprehensive documentation that aligns with user keywords and terms will be important for companies that want to surface their content in AI responses.

<h2>5. In an AI-driven future, will creating semantic, structured content be needed to optimize large language models' performance with company content?</h2>

<img src="https://s3.us-west-1.wasabisys.com/idbwmedia.com/images/aitechcommsurvey5.png" alt="Question 5" />

With *Likely 41%, very likely 29%*, this seems to be a nod to the DITA CCMS crowd, but some respondents might not understand structured authoring. In the freeform comments, some said "I can't quite parse this question." "Question is unclear..." "Not certain if I understood the question…"

The [Zoomin whitepaper](https://storage.pardot.com/1018802/1680517858gTb683bk/Zoomin_GPT_Key_Predictions_White_paper__1_.pdf) argues that " "...structured content … can dramatically help with the definition of content semantics to make the content highly optimized for programmatic consumption via search, filtering and personalization." And [Basques' post](https://technicalwriting.tools/posts/chatgpt-plugins/) emphasizes the need for developer docs to follow OpenAPI spec. 

However, by structured authoring, are we saying that content will need to be categorized as task, concept, reference, troubleshooting, and glossary content types, as well as other metadata indicating the version, language, operating system, and geographic regions, in order for AI to properly parse it? Given how language models work, which is by prediction, certainly the metadata could be helpful, but I'm skeptical of this recommendation based on the source. If your company touts structured authoring solutions, or if you're a consultant leaning heavily towards DITA, then would a prediction of a future that relies heavily on structure and semantics be susceptible with bias?

<h2>6. Do you think we'll soon transition from our AI hype cycle to an AI winter?</h2>

<img src="https://s3.us-west-1.wasabisys.com/idbwmedia.com/images/aitechcommsurvey6.png" alt="Question 6" />

It seems the audience is split on this one. A colleague asked me the other day, during lunch, if I'd ever seen anything similar to the AI explosion with another technology? I have been in the business for 18 solid years. I remember a heyday about crowdsourcing and wikis, and there was a fear that tech writer jobs would become obsolete through crowdsourcing. That never happened because it turns out people dislike writing docs, especially for commercially based corporations. But in this wave of AI, there's little effort in writing docs, especially if someone feeds engineers the right prompts to influence models with best practices. 

<h2>7. Given AI's rapid advancements, even if it's not possible today, do you think AI might be capable of writing the bulk of your documentation 12 months from now?</h2>

<img src="https://s3.us-west-1.wasabisys.com/idbwmedia.com/images/aitechcommsurvey7.png" alt="Question 7" />

This response is interesting because if AI tools can't write documentation a year from now, how will they be the disruptive, transformative engines that tech writers fear? One person says:

> AI won't fix all of the broken processes that need a human to untangle. It also assumes the content available to train the AI will always be of high quality which is laughable. AI doesn't know what is shipping or what changed and the bullet points handed over by PMs won't be enough.

I agree with this commenter. On a recent project, I pointed an AI tool at a proto file and asked it to generate docs. Then I proceeded to write docs for the project along with other team members. The output looked quite different because there was a lot of external context not present in the proto's comments, details that the AI tool couldn't know. Plus, someone wrote the comments in the first place, which the AI used for information. 

Perhaps if one could compile a large doc of all sources, including product design docs, engineering design docs, bug tickets, proto files, meeting transcriptions, and more and take all of this information and use it to synthesize the docs, then perhaps it could work. But so far, these models don't easily allow this kind of input unless you manually copy/paste it all into one doc. Even then, many have character limits and thread thresholds that constrain this kind of extended feeding of information.

<h2>Do you think existing documentation tools will evolve to include more AI-driven features?</h2>

<img src="https://s3.us-west-1.wasabisys.com/idbwmedia.com/images/aitechcommsurvey8.png" alt="Question 8" />

With *Very likely 61% and likely 32%,* I'm less optimistic about this transformation. Tech comm tools have limited resources and are usually slow to evolve and keep step with more popular web-based authoring tools. I fear that by the time they evolve, people will have migrated to more modern tools for most of the authoring. For example, once Bard is integrated into Google Docs or ChatGPT into MS Word and provides superior language generation and styling, my guess is that most people will author content in these tools and paste it into tech comm tools for the metadata and other publishing engine aspects. 

<h2>8. In the future, will writing become a less valuable skill due to AI's ability to write?</h2>

<img src="https://s3.us-west-1.wasabisys.com/idbwmedia.com/images/aitechcommsurvey9.png" alt="Question 9" />

The responses are split on this one: *Unlikely 30%, Likely 30%, Very likely: 13%, and Neutral: 16%.*

One commenter notes:

> Depends on the industry: real human writing could emerge the rare, more desirable commodity or only dominate expressly creative writing fields, such as poetry, fiction, playwriting, comparative lit, etc.

I do agree that creative writing will weather better against the AI storm than documentation. ChatGPT continues to tell me it doesn't have "personal opinions or emotions."  For example:

<img src="https://s3.us-west-1.wasabisys.com/idbwmedia.com/images/chatgptfos.png" alt="AI refuses to provide opinions" />

What kind of readers want to read content devoid of opinion or emotion? The only content left is explanatory/expository content, what you search for to find answers to questions. It's not the content you read when you want to pick up *The New Yorker* or someone's blog.

<h2>10. How do you think AI tools will write documentation for you?</h2>

<img src="https://s3.us-west-1.wasabisys.com/idbwmedia.com/images/aitechcommsurvey10.png" alt="Question 10" />

There weren't too many overwhelming trends here. Most people agreed with all the answers (except my fun one about mind reading). I think my list of options gives people a good idea about how AI tools might actually impact tech comm beyond merely writing documentation for you.

* Point the tools at source files and ask it to generate API documentation
* Identify trending topics by asking AI to scan through hundreds of ticket logs and surface the top threads
* Record a video of a process (e.g., completing a task in a UI), then ask AI to create a text-based version of the documentation
* Feed an AI tool a long code sample and ask it to break up the code into smaller, incremental steps with interspersed comments that build toward the full code 
* Create dynamically generated lists of recommended topics based on the user's browsing and search habits
* Convert recorded engineering demos into documentation
* Point AI tools at search query logs and ask it to write KB articles based on trending themes
* Write out documentation on the fly based on user-defined queries (rather than serving up documentation ahead of time)
* Ask engineers to create an outline of documentation, then ask AI to expand that outline into documentation

<h2>Insightful comments</h2>

The final survey question allowed respondents to provide freeform comments. The following are insightful comments I liked from both this question and others:

> Unless Oxygen, Adobe, or Help+Manual create Ai interfaces inside their software to generate content, a lot of the tech comm will be stuck in a 1990s desktop publishing mindset for a long time. I'm skeptical these companies will develop tools to allow such functionality or facilitate ways of migrating from those tools to ones which more easily allow Ai to handle the grunt work of typesetting and layout. For API documentation, it's another story.
<p></p>
> It will have a significant, negative impact. We will have people who are not writers publishing writing and all of the other tasks a writer would normally do that will disappear with the role will cause frustration and friction for companies who will struggle to understand what changed.
<p></p>
> ChatGPT 3.5 is great at regurgitating content which smells like what it was trained on, but asking it to create even modestly new features has been a big failure for me. While developers might need to become better prompt engineers, coming up with and documenting truely new ideas still requires humans.
<p></p>
> Developers are responsible for implementing AI and maintaining it. It was comical for everyone to get excited about writing roles becoming extinct, but the minute dev roles were on the table for replacement the call to slow down and assess was the focus on the next news cycle. They are actively securing their roles right now by making sure business leaders who don't understand AI think developers are critical to its success.
<p></p>
> I think that AI will speed up writing processes—for example by aggregating content on a particular topic based on search query to speed up the research process and to create first drafts of content based on a prompt. However, a person must still have contextual knowledge and expertise to assess accuracy and completeness. I suspect that AI is already being used to create KB and support articles based on the amount of support or troubleshooting content returned in Search that provides a lot of contextual info and wrote procedures but little of value for anything but the simplest use case and least complex problem. 
<p></p>
> This is very software-centric. Hardware docs are a totally different animal, as (I imagine) are medical docs, legal docs, etc. AI may have a greater ability to read code and spit out docs vs . trying to document hardware installation steps, regulatory documents, or medical labels.
<p></p>
> ChatGPT will reduce the skill gap for writing and reduce the number of writers requires to handle a project. However, if we come up with innovative ways of delivering content to users rather than the traditional pdf/html format, the impact may be different. We are in an uncharted territory now.
<p></p>
> New to the industry and honestly so very excited about this (and confused about the amount of fear tech writers have around this). Our company has been using ai to write content for well over a year before ChatGPT became public. And I was still hired. Our swes have already adapted their PR templates to include space for ai generated description of code, and for additional information provided by the engineer. This feeds our ai to create partial documentation which is supplemented by transcripts from video recordings, ai generated summaries from community threads, and internal threads about a topic. As a lone writer for a team of 50? "All" I have to do is ask the RIGHT questions to the team and create the RIGHT prompts/queries for ai generated content…
<p></p>
> I'm very interested in seeing the perspectives from non-semiconductor/software technical writers. The 'parroting' behavior would scare me if I were working in a company which has not patented technology to avoid giving clues to copycats, such as in rocket design or the defense industry. Or perhaps certain trade secrets in insurance or finance could be threatened... it seems that the onion analogy fits nicely here; with the outermost layers, where things are relatively the same across different companies in the same fields, but going deeper requires higher levels of understanding of core business principles and technology. I think we are still a ways off from AI independently devising new technologies, such as Star Trek's replicator, transporter, or warp drive, and documenting it.
<p></p>
> The possibilities are exciting, for sure, but I'm unsettled. AI is a prediction engine, not a truth teller, but it feels/sounds like a person talking to you, so I'm concerned that people will just take it at face value. We're in such a colossal mess right now with disinformation. We've shown that we're very susceptible to believing what we want to believe, and I suspect that this big AI splash is going to make this worse. Unfort! :(
<p></p>
> AI tools are currently useful for research. For example, you can point a tool to an entire website and ask for a summary of a topic. Likewise, you can ask for a summary of certain technology to save time sifting through multiple searches and going directly to the source. None of this information is useful as content, because it is likely all plagiarized and it is mostly to inform the writer regarding conventional wisdom. It is similar to reading Wikipedia articles to orient yourself regarding a subject. Grammar tools that use a sort of AI are also very valuable for quickly copy-editing large amounts of existing content.
<p></p>
> I'm already using ChatGPT in my job, and it is definitely changing my job. It's like having a pocket SME and junior writer that assists me and does some of the drudgery. My job is turning into more of an information organization role, which is not at all a bad thing. It's super nice having a resource to explain small code blocks or concepts, or to help me brainstorm headings and such. In the future, I think technical writers will feed information into an AI tool and direct the output, then organize the output so it is coherent. It's a great tool directed by a human mind.
<p></p>
>  Your question "Given AI's rapid advancements, even if it's not possible today, do you think AI might be capable of writing the bulk of your documentation 12 months from now?" -- it doesn't matter if I don't believe this is possible, if my workplace decides that that's true I am out of a job. Technical writing has been plagued with a lack of understanding as a profession and thus I can imagine every second engineer and product owner thinking that they will now not need a tech writer because they can use ChatGPT to write content. AI like this (and by the way, it's not "intelligent" as it is just dumbly writing out content based on algorithms) will create a static, biased content generator, stuck with 2020's language and (once again) bias as people ditch crafting their own words in favour of having a tool do this for them. 
<p></p>
> I hope AI takes away one aspect of the job for tech professionals: the gate keeping. I love seeing the opportunities in tech (or with tech) that AI tools have opened up for folks who don't "write good." I'm so bored of shop talking with other tech writers and their shopworn ideas. The robots are coming—but so are the humans. These humans who have so far been left out of the conversation are the ones I'm listening to.
<p></p>
> Current Chat-type AI can't write about what it doesn't know. Most information about technical products is tacit -- it exists in bits and pieces, often in the heads of product managers, developers, and support analysts. Such information is inaccessible to a search engine, but quite accessible to technical writers. The only role I see for Chat-type AI is as a super-search interface that can, if necessary, write new doc for a specific use case. But the AI will use existing content as the knowledge base, and that content will have to be generated the old-fashioned way, by technical writers.
<p></p>
> Where AI will shine in documentation will be the ability to respond to a query by providing specific information. For complex systems, documentation begins to fragment and task topics become too-many and hard to maintain. With an AI a user might ask "How to I create a user account and give them permission to view reports that show data for their store only?" And the AI will generate a list of steps to follow. With conversational AI, you can take it further, the user might ask, "OK, not how do I also give them permission to see the summary scores for other stores in their region." The AI would then provide the list of steps to alter the previous instructions to show how to complete the task. Long term, the AI will create the account for the user, when that happens, there won't be a need for user documentation. I would love to be able to use AI to say, "Give me a code snippet that shows how to query a user account and return the user's business title". I could then include that code as an example in the docs. Ideally, a developer should be able to make the same query and skip the documentation altogether.
<p></p>
> I think there will always be a place for technical writers as stewards/custodians/architects of information. As companies begin to trust AI with their own internal data however, the actual writing part will become devalued and therefore the demand/salary for tech writers will decrease. I believe that the place that's most likely to happen first is developer documentation (due to the highly-structured nature of code/API refs) which is unfortunately where my own skills lie. Time to re-evaluate my choice of career, I think :/
<p></p>
> I think the hype for AI is overblown and companies are falling all over themselves to build things that will be received very poorly by their customers. The train is being driven by developers who are fearful for their jobs and by people who devalue thinking. The idea that you can turn several poorly formatted bullet points into a proposal means we are going to be flooded by everyone's bad ideas. What happens when AI drafts an email, reads the response sent back to you, then sends a reply and you read a summary of it all in a digest. We are going to be quickly overwhelmed by our own AI generated output and will not be actively thinking or working anymore. But, hey we will be free of the struggle to write good.
<p></p>
> Definitely AI will change the way we write and document. AI will still need content to learn from, but part of the job can be covered. So yes, there is some concern into what are the limits of the AI... But on the positive side, chatbot might get better at answering queries from customer. And AI might be doing the heavy lifting of analysing tons of support ticket and surface up the important topics. One big concern is the bias and misinformation that will get out of proportion, this will require Doc steward role to make sure information is accurate.
<p></p>
> AI if anything will be a tool to aid in efficiency in creating documentation. It will not be able to handle the nuances or the critical thinking that technical writing demands nor a cohesiveness of information. If anything, AI will be a "best guess" approach to information.
<p></p>
> For professional writers, the questionable veracity of the content generated by the current crop of LLMs is the single biggest reason for not using them. They might evolve over time and hopefully become more reliable and trustworthy. A secondary issue is that LLM-generated content looks to be a legal minefield: - Are the creators of the latest LLMs on safe legal ground having trained their engines on a broad range of information found on the internet, including copyrighted works? (Probably not.) - Can content generated by a "machine" be copyrighted? (In general, no.) - Can the creators of LLMs be found liable for the consequences of providing dangerously wrong information? (Unless current laws are changed to accommodate AI systems, yes.) - Can the creator of a "machine" be held liable if he or she was negligent or reckless during the creation? (In theory, yes.)
<p></p>
> ... I hope that AI will be able to fish out the latest trends, what the developer community is talking about on hundreds of forums, blog posts, and threads/comments so we can use that information to write better content. 
<p></p>
> I think that AI will speed up writing processes—for example by aggregating content on a particular topic based on search query to speed up the research process and to create first drafts of content based on a prompt. However, a person must still have contextual knowledge and expertise to assess accuracy and completeness. 

<h2>Conclusion and takeaways</h2>

Based on the survey responses, I'm inclined to take the upcoming AI disruption seriously. I think it will go forward with all the anticipated transformation that people anticipate and fear. I'm inclined to look more into content strategy and information architecture as points of specialization, just as I'm also inclined to learn more about how to train LLMs for documentation purposes. And prompt engineering. But as one commenter noted, if the corporations become persuaded that they can dispense with their tech writers and have SMEs generate docs with AI, no matter how mediocre the output, there's likely little one can do. I can only hope there's a new crop of professions still being developed that will grow out of the AI transformation.