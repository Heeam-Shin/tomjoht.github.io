---
title: "First observations attempting to use my checklist"
categories:
- technical-writing
permalink: /blog/observations-using-checklist/
keywords: product overviews
description: "I recently published a comprehensive checklist for evaluating documentation quality. I have a few initial observations since publishing this."
bitlink:
---

## Observation 1: Limit the scope

My first observation is that developer portals are collaborative spaces where a lot of different writers interact, and you might own only a small piece of the portal. For example, there might be docs for 20 different products, with many different contributing teams. You might own docs for 2-3 products only. The user journey, however, might span the entire portal. Despite this, it's too daunting to focus on the entire portal in an initial assessment. It's more realistic to focus on the scope you own, at least initially.

## Observation 2: Two levels for checklists

My second observation is that many characteristics for docs can only be assessed when you're much more familiar with the docs. For example, you can't evaluate whether the steps in docs are actually accurate until you can go through them or gather more feedback from users. This isn't feasible without much more familiarity with the docs. In fact, you can't even tell if screenshots or other visuals are accurate without more familiarity. Because of this, I separated the checklist into a [first-level](/learnapidoc/docapis_metrics_first_level_checklist) and [second-level](/learnapidoc/docapis_metrics_second_level_checklist) checklist.

## Observation 3: Checklists aren't scannable

Checklists should be more scannable. I added bold summaries for each checklist item to make it more scannable at a glance.

## Observation 4: Page was too long

My initial page on measuring impact was about 8,000 words. I'm impressed that so many people actually read it from beginning to end. However, I decided to make the content more consumable by breaking it up into multiple pages. I moved the content out of the processes section into its own section on [Metrics and measurement](/learnapidoc/docapis_metrics_and_measurement). I plan to expand this section with additional info on metrics that go beyond documentation quality (though I don't have definitive plans there). I'm still trying to figure out what actually works when measuring API documentation quality. I'm not there yet. My content in this course is practically &mdash; it should actually work in practice, not just be theoretical.
